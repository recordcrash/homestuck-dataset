{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Converting Homestuck Collection data to an agnostic dataset\n",
    "\n",
    "This notebook has all the steps for taking data from the [Unofficial Homestuck Collection](https://bambosh.dev/unofficial-homestuck-collection/)'s asset pack and converting it into a dataset that can be used for training a machine learning model.\n",
    "\n",
    "Some planned uses for this are:\n",
    "- Summarization\n",
    "- Style transfer/LORAs\n",
    "- Chatbots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc6db19026c6712"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constants and Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a5b4fe83d23a00"
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "IMPORTS\n",
    "Put all at the beginning because I hate notebooks so much\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import base64\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T15:38:57.570293Z",
     "start_time": "2024-09-25T15:38:56.673319Z"
    }
   },
   "id": "a96f77f5afe024c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "CONSTANTS\n",
    "This will extract constants from the env variables set in the .env file \n",
    "and make them accessible to the notebook\n",
    "\"\"\"\n",
    "print(\"Loading variables from .env file\\n...\")\n",
    "load_dotenv()\n",
    "\n",
    "ASSET_PACK_FOLDER = os.getenv(\"ASSET_PACK_FOLDER\")\n",
    "OUTPUT_FOLDER = os.getenv(\"OUTPUT_FOLDER\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API\")\n",
    "MODEL_ID = os.getenv(\"MODEL_ID\")\n",
    "print(\"Loaded variables successfully\")\n",
    "    \n",
    "print(\"Loading constants\\n...\")\n",
    "# Relevant folders and files\n",
    "\n",
    "# Bespoke input files that aren't available elsewhere\n",
    "INPUT_FOLDER = os.path.join(os.path.dirname(os.path.abspath('')), \"input\")\n",
    "\n",
    "# Transcripts and commentary from ReadMSPA, assembled by Bambosh, Makin and Giovanh\n",
    "MSPA_TRANSCRIPTS_FILE = os.path.join(INPUT_FOLDER, \"transcripts.json\")\n",
    "MSPA_COMMENTARY_FILE = os.path.join(INPUT_FOLDER, \"commentary.json\")\n",
    "# Panel tags from the Homestuck Search Engine\n",
    "HSSE_TAGS_FILE = os.path.join(INPUT_FOLDER, \"hsse_tags.json\")\n",
    "HSSE_SEARCH_FILE = os.path.join(INPUT_FOLDER, \"hsse_search.json\")\n",
    "\n",
    "# POV cam data folder with txt files\n",
    "POV_CAM_FOLDER = os.path.join(INPUT_FOLDER, \"readable_timelines\")\n",
    "\n",
    "# Homestuck Collection's asset pack data folder\n",
    "COLLECTION_DATA_FOLDER = os.path.join(ASSET_PACK_FOLDER, \"archive/data\")\n",
    "\n",
    "# Holds all the text in MS Paint Adventures, including Homestuck\n",
    "MSPA_TEXT_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"mspa.json\")\n",
    "# Holds the text for news posts\n",
    "NEWS_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"news.json\")\n",
    "# Holds the text for social media posts\n",
    "SOCIAL_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"social.json\")\n",
    "# Most of this is irrelevant, but holds images for additional Hussie comics\n",
    "# such as Team Special Olympics\n",
    "ADDITIONAL_COMICS_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"comics.json\")\n",
    "# Holds panels\n",
    "PANELS_FOLDER = os.path.join(ASSET_PACK_FOLDER, \"storyfiles\")\n",
    "HS_PANELS_FOLDER = os.path.join(PANELS_FOLDER, \"hs2\")\n",
    "\n",
    "print(\"Loaded constants successfully\")\n",
    "      \n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(f\"OpenAI client loaded with model {MODEL_ID}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T15:39:49.706731Z",
     "start_time": "2024-09-25T15:39:49.689187Z"
    }
   },
   "id": "e78f80818098b035",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from .env file\n",
      "...\n",
      "Loaded variables successfully\n",
      "Loading constants\n",
      "...\n",
      "Loaded constants successfully\n",
      "OpenAI client loaded with model gpt-4o\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract MSPA data from Asset Pack\n",
    "\n",
    "First of all, we want to open the MSPA_TEXT_JSON and fetch all the text data from it. This will be the main source of text data for our dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bee659a168b55b1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nThe JSON is structured in a way that makes it easy to extract the text data, but we can make it better.\\n\\nFor each image, an accompanying JSON:\\n{\\n    \"pageId\": \"000006\",  # The unique identifier for the page\\n    \"order\": 0,  # Its position in the page (multipanels will have 0-n...)\\n    \"type\": \"animated\",  # \"animated\", \"static\"\\n    \"textDescription\": \"...\"  # For generating this, we can use image models and the text transcripts from readmspa,\\n    \"tags\": [] # Tags for the image, characters, locations, etc. we can extract some from the character POV extension and image search,\\n    \"author\": \"Andrew Hussie\", # 99% of these will be Andrew, but very rarely we\\'ll see external art (\"Other\") or by known artists (\"Adrienne Garcia\")\\n}\\nThis is a better format for the first ML dataset:\\n{\\n    \\n    \"story\": \"Homestuck\"\\n    \"pageId\": \"001902\",\\n    \"title\": \"Enter name\",\\n    \"content\": \"...\",\\n    \"html_content\": \"...\",\\n    \"media\": [\\n        {\\n            \\n        }\\n    ],\\n    \"tags\": [], # Character and other tags for the text depending on the type of content \\n    \"next\": \"001903\",\\n    \"next_title\": \"Try again.\",\\n}\\n\\nWe\\'ll have other datasets with things like the entirety of Hussie\\'s text in one place, or just the images... we\\'ll think about it\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MSPA_TEXT_JSON format:\n",
    "{\n",
    "  \"story\": {  # The text in MS Paint Adventures, the comics themselves\n",
    "    \"000006\": {\n",
    "      \"title\": \"Look for keyhole\",\n",
    "      \"pageId\": \"000006\",\n",
    "      \"timestamp\": \"1180921880\",\n",
    "      \"flag\": [],\n",
    "      \"media\": [\n",
    "        \"/advimgs/jb/mspaintadventure04.gif\",\n",
    "        \"/advimgs/jb/mspaintadventure04b.gif\"\n",
    "      ],\n",
    "      \"content\": \"\",\n",
    "      \"next\": [\n",
    "        \"000008\"\n",
    "      ],\n",
    "      \"previous\": \"000005\",\n",
    "      \"theme\": \"retro\"\n",
    "    },\n",
    "    \"000009\": {\n",
    "      \"title\": \"Loudly tell that guy to pick up key and try it on the door.\",\n",
    "      \"pageId\": \"000009\",\n",
    "      \"timestamp\": \"1180931172\",\n",
    "      \"flag\": [],\n",
    "      \"media\": [\n",
    "        \"/advimgs/jb/mspaintadventure06.gif\"\n",
    "      ],\n",
    "      \"content\": \"Despite your bellowing, the man casually opens the door and leaves.\",\n",
    "      \"next\": [\n",
    "        \"000010\"\n",
    "      ],\n",
    "      \"previous\": \"000008\",\n",
    "      \"theme\": \"retro\"\n",
    "    },\n",
    "  },...\n",
    "  \"ryanquest\": {...},  # Additional Ryanquest comic\n",
    "  \"psExtras\": {...}, # Bonus pages for Problem Sleuth\n",
    "  \"wv\": {...}, # \"Exile\" Homestuck pages, should be processed just like the \"story\" pages\n",
    "  \"faqs\": {\n",
    "    \"general\": {\n",
    "      \"title\": \"General FAQ - MS Paint Adventures\",\n",
    "      \"pageId\": \"general\",\n",
    "      \"content\": \"...\" # html\n",
    "    },\n",
    "    \"new\": {...},  # New reader guide\n",
    "    \"science\": {...},  # Science FAQ\n",
    "    \"sales\": {...}, # This one was probably not Hussie, so ignore\n",
    "  },\n",
    "  # Other keys are fully irrelevant\n",
    "\"\"\"\n",
    "\n",
    "def extract_mspa_data():\n",
    "    with open(MSPA_TEXT_JSON, 'r', encoding='utf-8') as f:\n",
    "        mspa_data = json.load(f)\n",
    "    return mspa_data\n",
    "\n",
    "mspa_data = extract_mspa_data()\n",
    "\n",
    "\"\"\"\n",
    "The JSON is structured in a way that makes it easy to extract the text data, but we can make it better.\n",
    "\n",
    "For each image, an accompanying JSON:\n",
    "{\n",
    "    \"pageId\": \"000006\",  # The unique identifier for the page\n",
    "    \"order\": 0,  # Its position in the page (multipanels will have 0-n...)\n",
    "    \"type\": \"animated\",  # \"animated\", \"static\"\n",
    "    \"textDescription\": \"...\"  # For generating this, we can use image models and the text transcripts from readmspa,\n",
    "    \"tags\": [] # Tags for the image, characters, locations, etc. we can extract some from the character POV extension and image search,\n",
    "    \"author\": \"Andrew Hussie\", # 99% of these will be Andrew, but very rarely we'll see external art (\"Other\") or by known artists (\"Adrienne Garcia\")\n",
    "}\n",
    "This is a better format for the first ML dataset:\n",
    "{\n",
    "    \n",
    "    \"story\": \"Homestuck\"\n",
    "    \"pageId\": \"001902\",\n",
    "    \"title\": \"Enter name\",\n",
    "    \"content\": \"...\",\n",
    "    \"html_content\": \"...\",\n",
    "    \"media\": [\n",
    "        {\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    \"tags\": [], # Character and other tags for the text depending on the type of content \n",
    "    \"next\": \"001903\",\n",
    "    \"next_title\": \"Try again.\",\n",
    "}\n",
    "\n",
    "We'll have other datasets with things like the entirety of Hussie's text in one place, or just the images... we'll think about it\n",
    "\"\"\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T12:05:22.092261Z",
     "start_time": "2024-05-17T12:05:21.951258Z"
    }
   },
   "id": "b0caa83cdb1203fb",
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting panel transcripts from ReadMSPA plugin\n",
    "\n",
    "ReadMSPA's data (and its plugin from the collection) comes with text transcripts of every image's text, if not descriptions. We can use that."
   ],
   "id": "7769fbbcf399e4c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T16:59:22.013768Z",
     "start_time": "2024-09-25T16:59:22.009878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "The ReadMSPA data is... TODO\n",
    "\"\"\""
   ],
   "id": "5776d1d18e08d406",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe ReadMSPA data is... TODO\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting panel tags from HSSE\n",
    "\n",
    "The Homestuck Search Engine people tagged the tags of the first four acts, from characters to locations and more. Will be extremely useful for image transcription."
   ],
   "id": "b8d3d687bdf45636"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T16:59:23.712820Z",
     "start_time": "2024-09-25T16:59:23.706455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "HSSE_TAGS_FILE and HSSE_SEARCH file contain the entirety of the Homestuck Search Engine tagged data (only the first four acts, until page 1988 inclusive and excluding some swfs) in its own bespoke JSON format.\n",
    "HSSE_TAGS_FILE is the simpler json with tag definitions, and which tags contain other tags:\n",
    "```\n",
    " \"definitions\": {\n",
    "    \"0\": {\n",
    "      \"_id\": 0,\n",
    "      \"name\": \"Character\",\n",
    "      \"children\": [\n",
    "        1,\n",
    "        32,\n",
    "        56,\n",
    "        60,\n",
    "        104,\n",
    "        132,\n",
    "        148,\n",
    "        155,\n",
    "        173,\n",
    "        184,\n",
    "        253\n",
    "      ]\n",
    "    },\n",
    "    \"1\": {\n",
    "      \"_id\": 1,\n",
    "      \"name\": \"Human\",\n",
    "      \"children\": [\n",
    "        2,\n",
    "        15\n",
    "      ]\n",
    "    },\n",
    "    \"2\": {\n",
    "      \"_id\": 2,\n",
    "      \"name\": \"Kid\",\n",
    "      \"children\": [\n",
    "        3,\n",
    "        10\n",
    "      ]\n",
    "    },\n",
    "    \"3\": {\n",
    "      \"_id\": 3,\n",
    "      \"name\": \"Beta Kid\",\n",
    "      \"children\": [\n",
    "        4,\n",
    "        5,\n",
    "        7,\n",
    "        9\n",
    "      ]\n",
    "    },\n",
    "    \"4\": {\n",
    "      \"_id\": 4,\n",
    "      \"name\": \"John Egbert\",\n",
    "      \"children\": []\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "\n",
    "HSSE_SEARCH_FILE is the more complex json with the actual tags for each panel:\n",
    "[\n",
    "  {\n",
    "    \"_id\": 0,\n",
    "    \"type\": 0,\n",
    "    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\n",
    "    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\n",
    "    \"url\": \"https://homestuck.com/story/1\",\n",
    "    \"tags\": [\n",
    "      1384,\n",
    "      1385,\n",
    "      391,\n",
    "      321,\n",
    "      4,\n",
    "      749,\n",
    "      801,\n",
    "      1301,\n",
    "      602,\n",
    "      1192,\n",
    "      711,\n",
    "      1349\n",
    "    ],\n",
    "    \"page\": 1\n",
    "  },\n",
    "  {\n",
    "    \"_id\": 1,\n",
    "    \"type\": 0,\n",
    "    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\n",
    "    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\n",
    "    \"url\": \"https://homestuck.com/story/2\",\n",
    "    \"tags\": [\n",
    "      1384,\n",
    "      1385,\n",
    "      391,\n",
    "      321,\n",
    "      4,\n",
    "      1349,\n",
    "      602\n",
    "    ],\n",
    "    \"page\": 2\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "Our objective here is to combine the information so that, for each page, we'll have its human readable tags. \n",
    "\"\"\""
   ],
   "id": "d7f364527cfaaabf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHSSE_TAGS_FILE and HSSE_SEARCH file contain the entirety of the Homestuck Search Engine tagged data (only the first four acts, until page 1988 inclusive and excluding some swfs) in its own bespoke JSON format.\\nHSSE_TAGS_FILE is the simpler json with tag definitions, and which tags contain other tags:\\n```\\n \"definitions\": {\\n    \"0\": {\\n      \"_id\": 0,\\n      \"name\": \"Character\",\\n      \"children\": [\\n        1,\\n        32,\\n        56,\\n        60,\\n        104,\\n        132,\\n        148,\\n        155,\\n        173,\\n        184,\\n        253\\n      ]\\n    },\\n    \"1\": {\\n      \"_id\": 1,\\n      \"name\": \"Human\",\\n      \"children\": [\\n        2,\\n        15\\n      ]\\n    },\\n    \"2\": {\\n      \"_id\": 2,\\n      \"name\": \"Kid\",\\n      \"children\": [\\n        3,\\n        10\\n      ]\\n    },\\n    \"3\": {\\n      \"_id\": 3,\\n      \"name\": \"Beta Kid\",\\n      \"children\": [\\n        4,\\n        5,\\n        7,\\n        9\\n      ]\\n    },\\n    \"4\": {\\n      \"_id\": 4,\\n      \"name\": \"John Egbert\",\\n      \"children\": []\\n    },\\n    ...\\n}\\n\\nHSSE_SEARCH_FILE is the more complex json with the actual tags for each panel:\\n[\\n  {\\n    \"_id\": 0,\\n    \"type\": 0,\\n    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\\n    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\\n    \"url\": \"https://homestuck.com/story/1\",\\n    \"tags\": [\\n      1384,\\n      1385,\\n      391,\\n      321,\\n      4,\\n      749,\\n      801,\\n      1301,\\n      602,\\n      1192,\\n      711,\\n      1349\\n    ],\\n    \"page\": 1\\n  },\\n  {\\n    \"_id\": 1,\\n    \"type\": 0,\\n    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\\n    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\\n    \"url\": \"https://homestuck.com/story/2\",\\n    \"tags\": [\\n      1384,\\n      1385,\\n      391,\\n      321,\\n      4,\\n      1349,\\n      602\\n    ],\\n    \"page\": 2\\n  },\\n  ...\\n]\\n```\\nOur objective here is to combine the information so that, for each page, we\\'ll have its human readable tags. \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extracting character appearances from POV cam \n",
    "\n",
    "The POV cam extension for Homestuck allows us to see the characters that are present in each page, and not just until page 1988, all of them. We can use this to extract character tags and somewhat make up for the lack of tags in the later pages."
   ],
   "id": "7b3267621db2deb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T17:10:09.637556Z",
     "start_time": "2024-09-25T17:10:09.627669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "The data from the POV cam comes in many files named after each character, like \"roxy.txt\" and \"rufioh.txt\". The format is not meant to be easily parsable, but it shouldn't be too hard to extract the data and \"invert\" it, to get the characters that appear in each page and their \"commands\".\n",
    "\n",
    "An example of the data (jade.txt):\n",
    "```\n",
    "Name: Jade\n",
    "Colour: #4AC925\n",
    "Image: jade.png\n",
    "Group: Kids\n",
    "\n",
    "Be created on meteor\n",
    "3790-3791\n",
    "3803\n",
    "3807\n",
    "3830-3831\n",
    "\n",
    "Be sent to Earth\n",
    "3840\n",
    "\n",
    "Land on factory\n",
    "3768-3769\n",
    "\n",
    "Be adopted\n",
    "3773-3775\n",
    "\n",
    "Be taken on hunt with grandfather\n",
    "Wander off with Bec\n",
    "Find present\n",
    "3029-3036\n",
    "```\n",
    "From the documentation:\n",
    "```md\n",
    "## Timeline language\n",
    "\n",
    "In the `Readable Timelines` folder are a number of files, each containing the timeline data for a single person.\n",
    "\n",
    "The files use the following format:\n",
    "\n",
    " * Page numbers or ranges of numbers to describe what pages a person's on.\n",
    "   (For A6A5A1x2 COMBO, use `-2` on the end to go through the pages two at a time)\n",
    "   eg. `6009`, `1901-2032`, or `7688-7692-2`\n",
    " * To split the timeline, indent the splintered timeline, then return to the original indentation for the alpha timeline.\n",
    "   Note that the two timelines are not connected by default, you must use the next two commands to describe how they should be joined.\n",
    " * `==>`: Jump into the next split timeline from this point\n",
    " * `<==`: Jump out of previous split timeline to this point\n",
    " * `~`: Insert another timeline here, using a person's name.\n",
    "   eg. `~ Davesprite`\n",
    "\n",
    "The following commands change properties about the current person or timeline.\n",
    "Write the exact word, then `:`, then the value you wish to set it to.\n",
    "eg. `Name: John`.\n",
    "\n",
    " * `Name`: Change the name of the current person.\n",
    " * `Colour`: Change the colour used for the links.\n",
    " * `Image`: Change the image used for the links.\n",
    " * `Group`: Change which group the links are a part of.\n",
    " * `Caption`: Give some hover-over text to the link between the previous page and the next.\n",
    "\n",
    "All lines which do not fit any of the above are ignored, like comments.\n",
    "```\n",
    "\n",
    "Here's also the timelines.py file used to compile it for the extension:\n",
    "\n",
    "```py\n",
    "from collections import defaultdict, OrderedDict\n",
    "import re\n",
    "\n",
    "from timeline_compiler.objects import Person, Link\n",
    "\n",
    "\n",
    "class Timelines:\n",
    "    patterns = {\n",
    "        \"Pages\": re.compile(\"^\\d+(-\\d+(-2)?)?$\"),\n",
    "        \"==>\": re.compile(\"^=+>$\"),\n",
    "        \"<==\": re.compile(\"^<=+$\"),\n",
    "        \"GOTO\": re.compile(\"^~\\s*[\\w ()'^]+$\", re.IGNORECASE),\n",
    "        \"Name\": re.compile(\"^Name:\\s*[\\w ()'^]+$\", re.IGNORECASE),\n",
    "        \"Colour\": re.compile(\"^Colour:\\s*#[0-9A-F]{6}$\", re.IGNORECASE),\n",
    "        \"Image\": re.compile(\"^Image:\\s*\\w+\\.\\w+$\", re.IGNORECASE),\n",
    "        \"Group\": re.compile(\"^Group:\\s*[\\w ()']+$\", re.IGNORECASE),\n",
    "        \"Caption\": re.compile(\"^Caption:\\s*[\\w ]+$\", re.IGNORECASE)\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colours = []\n",
    "        self.images = []\n",
    "        self.groups = []\n",
    "\n",
    "        self.people = OrderedDict()\n",
    "        self.next_page_links = defaultdict(list)\n",
    "\n",
    "    def get_person(self, person_name):\n",
    "        if person_name not in self.people:\n",
    "            self.people[person_name] = Person(len(self.people), person_name)\n",
    "        return self.people[person_name]\n",
    "\n",
    "    @classmethod\n",
    "    def tokenize_timeline_file(cls, timeline_file_location):\n",
    "        with open(timeline_file_location, 'r') as timeline_file:\n",
    "            yield from cls.tokenize_timeline_statements(timeline_file)\n",
    "\n",
    "    @classmethod\n",
    "    def tokenize_timeline_statements(cls, statements):\n",
    "        indent_level = 0\n",
    "        for line in statements:\n",
    "            potential_command = line.strip()\n",
    "            pattern_match = next((pattern for pattern in cls.patterns if cls.patterns[pattern].match(potential_command)), None)\n",
    "\n",
    "            if pattern_match is None:\n",
    "                continue\n",
    "\n",
    "            # Good enough in most cases\n",
    "            # May want to improve later\n",
    "            next_indent_level = len(line) - len(line.lstrip())\n",
    "            if next_indent_level > indent_level:\n",
    "                yield (\"BOT\",)\n",
    "            elif next_indent_level < indent_level:\n",
    "                yield (\"EOT\",)\n",
    "            indent_level = next_indent_level\n",
    "\n",
    "            if pattern_match == \"Pages\":\n",
    "                args = [int(s) for s in potential_command.split(\"-\")]\n",
    "                if len(args) == 1:\n",
    "                    args.append(args[0])\n",
    "                args[1] += 1\n",
    "                yield (pattern_match,) + tuple(args)\n",
    "\n",
    "            elif pattern_match == \"GOTO\":\n",
    "                yield (pattern_match, potential_command[1:].strip())\n",
    "\n",
    "            elif pattern_match in {\"Name\", \"Colour\", \"Image\", \"Group\", \"Caption\"}:\n",
    "                yield (pattern_match, potential_command.split(\":\")[1].strip())\n",
    "\n",
    "            else:\n",
    "                yield (pattern_match,)\n",
    "\n",
    "        yield (\"EOT\",)\n",
    "\n",
    "    def add_timeline(self, timeline_file_location):\n",
    "        self.exec_timeline_tokens(self.tokenize_timeline_file(timeline_file_location))\n",
    "\n",
    "    def exec_timeline_tokens(self, command_iterator, previous_pages=None, current_person=None, current_colour=None, current_image=None, current_group=None, next_caption=None):\n",
    "        # Page to pass into next splinter timeline\n",
    "        splinter_pages = []\n",
    "        # Page returned from splinter timeline\n",
    "        return_pages = []\n",
    "\n",
    "        if previous_pages is None:\n",
    "            previous_pages = []\n",
    "\n",
    "        for command, *args in command_iterator:\n",
    "            if command == \"Pages\":\n",
    "                for page_number in range(*args):\n",
    "                    next_link = Link(page_number, current_person, current_colour, current_image, current_group)\n",
    "\n",
    "                    if isinstance(current_person, Person) and current_person.first_page is None:\n",
    "                        current_person.first_page = next_link\n",
    "\n",
    "                    self.next_page_links[page_number].append(next_link)\n",
    "\n",
    "                    for page in previous_pages:\n",
    "                        page.link_to(next_link, next_caption)\n",
    "                    previous_pages = [next_link]\n",
    "                    next_caption = None\n",
    "\n",
    "            elif command == \"==>\":\n",
    "                splinter_pages = previous_pages\n",
    "\n",
    "            elif command == \"<==\":\n",
    "                previous_pages.extend(return_pages)\n",
    "\n",
    "            elif command == \"GOTO\":\n",
    "                for page in previous_pages:\n",
    "                    page.link_to(args[0])\n",
    "                previous_pages = [Link(args[0])]\n",
    "                self.next_page_links[args[0]].append(previous_pages[0])\n",
    "                next_caption = None\n",
    "\n",
    "            elif command == \"EOT\":\n",
    "                current_person.last_pages = previous_pages\n",
    "                return previous_pages\n",
    "\n",
    "            elif command == \"BOT\":\n",
    "                return_pages = self.exec_timeline_tokens(command_iterator, splinter_pages, current_person, current_colour, current_image, current_group)\n",
    "                splinter_pages = []\n",
    "\n",
    "            elif command == \"Name\":\n",
    "                current_person = self.get_person(args[0])\n",
    "\n",
    "            elif command == \"Colour\":\n",
    "                if not args[0] in self.colours:\n",
    "                    self.colours.append(args[0])\n",
    "                current_colour = self.colours.index(args[0])\n",
    "\n",
    "            elif command == \"Image\":\n",
    "                if not args[0] in self.images:\n",
    "                    self.images.append(args[0])\n",
    "                current_image = self.images.index(args[0])\n",
    "\n",
    "            elif command == \"Group\":\n",
    "                if not args[0] in self.groups:\n",
    "                    self.groups.append(args[0])\n",
    "                current_group = self.groups.index(args[0])\n",
    "\n",
    "            elif command == \"Caption\":\n",
    "                next_caption = args[0]\n",
    "```\n",
    "\n",
    "Ideally the end format would be a pandas dataframe with the following columns:\n",
    "- pageId\n",
    "- character\n",
    "- command\n",
    "\"\"\"\n",
    "\n",
    "def extract_data_from_pov_cam_file(pov_cam_file: str) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "def extract_pov_cam_data():\n",
    "    pov_cam_files = os.listdir(POV_CAM_FOLDER)\n",
    "    pov_cam_data = pd.concat([extract_data_from_pov_cam_file(file) for file in pov_cam_files])\n",
    "    return pov_cam_data"
   ],
   "id": "ffcf872b5d200fc4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transcribing panels\n",
    "\n",
    "We have the panel images, we have the ReadMSPA transcripts of them, we have the point of view from the POV cam, and we have the title and text that accompanies the panels. We have some partial tagging information from the Homestuck Search engine. With that and a vision model, we might be able to successfully extract non-hallucinated information."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b474359994b684b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"characters\": [\"John Egbert\", \"Rose Lalonde\", \"Dr. Meowgon Spengler\"],\n",
      "    \"description\": \"John Egbert stands in a cluttered room, wearing a green suit with a blue tie. He is smiling and looking at a small black cat, which he has decided to name Dr. Meowgon Spengler. Rose Lalonde is asleep on the floor, with a 'Z' text bubble above her head, indicating she is sleeping. The room is messy, with various objects scattered around, including a laptop on a desk, a purple cube, and a red rocket-like object hanging from the ceiling. The wall in the background has the word 'MEOW' written repeatedly in purple.\",\n",
      "    \"locations\": [\"Rose's House\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Queries to send to the annotation model\n",
    "batch_queries = []\n",
    "system_prompt =  \"\"\"You are a professional image annotator.\n",
    "Your current project is annotating the panels of the webcomic Homestuck. You need to write a textual description as well as a list of location and character tags.\n",
    "Your input will be the image file itself, the source comic, the page title, the current POV characters and the OCR transcript of all the text in the page. For example:\n",
    "{\n",
    "    \"src\": \"005624.gif\",\n",
    "    \"title\": \"Jane: Reply\",\n",
    "    \"pov_characters\": [\"Jane Crocker\", \"Caliborn\"],\n",
    "    \"transcript\": [\"...\", \"HELP\"]\n",
    "}\n",
    "This is an example output:\n",
    "{\n",
    "    \"characters\": [\"Jane Crocker\"],\n",
    "    \"locations\": [\"Land of Crypts and Helium\", \"Jane's House\"],  # If you don't know the location, just leave it out\n",
    "    \"description\": \"Jane Crocker stands in the middle of her room, next to her bed. Jane is wearing a gray shirt with a blue monster logo on it, as well as a blue skirt. The room contains posters of movies. Outside the window we can see the Land of Crypts and Helium, a gray planet with multicolored flowers. There's a text bubble with '...' pointing to her head.\",\n",
    "}\n",
    "You should write verbose descriptions that will be useful for people who can't see the image, as well as for training image models.\n",
    "No talk; just go.\n",
    "\"\"\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "\n",
    "def annotate_panel(panel_data: dict, image_path: str) -> dict:\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": json.dumps(panel_data)\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\", \n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{encode_image(image_path)}\"\n",
    "                }\n",
    "            }\n",
    "        ]}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_panel_data(panel_id: str) -> dict:\n",
    "    # We get metadata from a variety of sources\n",
    "    # src: the image file name\n",
    "    # title, page_content: from the json archive\n",
    "    # pov_characters: from the POV extension\n",
    "    # transcript: from the ReadMSPA transcripts\n",
    "    pass\n",
    "    \n",
    "\n",
    "# We load a test panel, from HS_PANELS_FOLDER, 01691.gif which should depict a sleeping Rose and an awake John\n",
    "test_panel = os.path.join(HS_PANELS_FOLDER, \"01691.gif\")\n",
    "test_panel_data = {\n",
    "    \"src\": \"01691.gif\",\n",
    "    \"title\": \"John: Get up.\",\n",
    "    \"page_content\": \"\"\"Despite the pandemonium of your entrance, Rose is still sound asleep. She must be really tuckered out!\n",
    "<br>\n",
    "<br>It looks like this little guy is awake and ready for action though. He is adorable. You decide to name him Dr. Meowgon Spengler.\"\"\",\n",
    "    \"pov_characters\": [\"John Egbert\", \"Rose Lalonde\"],\n",
    "    \"transcript\": [\"Z\"],\n",
    "}\n",
    "\n",
    "# We'll use the OpenAI API to annotate the panel\n",
    "# This is a test, so we'll just print the output\n",
    "print(annotate_panel(test_panel_data, test_panel))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T12:06:43.588686Z",
     "start_time": "2024-05-17T12:06:39.635601Z"
    }
   },
   "id": "cedb5ad02fa9ded7",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Textual datasets\n",
    "\n",
    "We output datasets for Homestuck, MS Paint Adventures as a whole, and all of Andrew Hussie's works.\n",
    "\n",
    "The format is .jsonl"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f38d16f8b794cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-17T12:05:22.907068Z"
    }
   },
   "id": "844d7091d210b86f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
