{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Converting Homestuck Collection data to an agnostic dataset\n",
    "\n",
    "This notebook has all the steps for taking data from the [Unofficial Homestuck Collection](https://bambosh.dev/unofficial-homestuck-collection/)'s asset pack and converting it into a dataset that can be used for training a machine learning model.\n",
    "\n",
    "Some planned uses for this are:\n",
    "- Summarization\n",
    "- Style transfer/LORAs\n",
    "- Chatbots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc6db19026c6712"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constants and Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a5b4fe83d23a00"
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "IMPORTS\n",
    "Put all at the beginning because I hate notebooks so much\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import base64\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T15:38:57.570293Z",
     "start_time": "2024-09-25T15:38:56.673319Z"
    }
   },
   "id": "a96f77f5afe024c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T15:28:14.065487Z",
     "start_time": "2024-09-28T15:28:14.040647Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from .env file\n",
      "...\n",
      "Loaded variables successfully\n",
      "Loading constants\n",
      "...\n",
      "Loaded constants successfully\n",
      "OpenAI client loaded with model gpt-4o\n"
     ]
    }
   ],
   "execution_count": 60,
   "source": [
    "\n",
    "\"\"\"\n",
    "CONSTANTS\n",
    "This will extract constants from the env variables set in the .env file \n",
    "and make them accessible to the notebook\n",
    "\"\"\"\n",
    "print(\"Loading variables from .env file\\n...\")\n",
    "load_dotenv()\n",
    "\n",
    "ASSET_PACK_FOLDER = os.getenv(\"ASSET_PACK_FOLDER\")\n",
    "OUTPUT_FOLDER = os.getenv(\"OUTPUT_FOLDER\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API\")\n",
    "MODEL_ID = os.getenv(\"MODEL_ID\")\n",
    "print(\"Loaded variables successfully\")\n",
    "    \n",
    "print(\"Loading constants\\n...\")\n",
    "# Relevant folders and files\n",
    "\n",
    "# Bespoke input files that aren't available elsewhere\n",
    "INPUT_FOLDER = os.path.join(os.path.dirname(os.path.abspath('')), \"input\")\n",
    "\n",
    "# Transcripts and commentary from ReadMSPA, assembled by Bambosh, Makin and Giovanh\n",
    "MSPA_COMMENTARY = os.path.join(INPUT_FOLDER, \"commentary.json\")\n",
    "\n",
    "# Full transcripts from ReadMSPA, assembled by Giovanh and Bambosh\n",
    "READMSPA_ALTNARRATIVE = os.path.join(INPUT_FOLDER, \"altnarrative.json\")\n",
    "READMSPA_ALTTEXT = os.path.join(INPUT_FOLDER, \"alttext.json\")\n",
    "READMSPA_TRANSCRIPTS = os.path.join(INPUT_FOLDER, \"transcripts.json\")\n",
    "\n",
    "# Panel tags from the Homestuck Search Engine\n",
    "HSSE_TAGS = os.path.join(INPUT_FOLDER, \"hsse_tags.json\")\n",
    "HSSE_SEARCH = os.path.join(INPUT_FOLDER, \"hsse_search.json\")\n",
    "\n",
    "# POV cam data folder with txt files\n",
    "POV_CAM_FOLDER = os.path.join(INPUT_FOLDER, \"readable_timelines\")\n",
    "\n",
    "# Homestuck Collection's asset pack data folder\n",
    "COLLECTION_DATA_FOLDER = os.path.join(ASSET_PACK_FOLDER, \"archive/data\")\n",
    "\n",
    "# Holds all the text in MS Paint Adventures, including Homestuck\n",
    "MSPA_TEXT_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"mspa.json\")\n",
    "# Holds the text for news posts\n",
    "NEWS_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"news.json\")\n",
    "# Holds the text for social media posts\n",
    "SOCIAL_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"social.json\")\n",
    "# Most of this is irrelevant, but holds images for additional Hussie comics\n",
    "# such as Team Special Olympics\n",
    "ADDITIONAL_COMICS_JSON = os.path.join(COLLECTION_DATA_FOLDER, \"comics.json\")\n",
    "# Holds panels\n",
    "PANELS_FOLDER = os.path.join(ASSET_PACK_FOLDER, \"storyfiles\")\n",
    "HS_PANELS_FOLDER = os.path.join(PANELS_FOLDER, \"hs2\")\n",
    "\n",
    "print(\"Loaded constants successfully\")\n",
    "      \n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(f\"OpenAI client loaded with model {MODEL_ID}\")"
   ],
   "id": "e78f80818098b035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extract MSPA data from Asset Pack\n",
    "\n",
    "First of all, we want to open the MSPA_TEXT_JSON and fetch all the text data from it. This will be the main source of text data for our dataset."
   ],
   "id": "17e20116190292f1"
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "MSPA_TEXT_JSON format:\n",
    "{\n",
    "  \"story\": {  # The text in MS Paint Adventures, the comics themselves\n",
    "    \"000006\": {\n",
    "      \"title\": \"Look for keyhole\",\n",
    "      \"pageId\": \"000006\",\n",
    "      \"timestamp\": \"1180921880\",\n",
    "      \"flag\": [],\n",
    "      \"media\": [\n",
    "        \"/advimgs/jb/mspaintadventure04.gif\",\n",
    "        \"/advimgs/jb/mspaintadventure04b.gif\"\n",
    "      ],\n",
    "      \"content\": \"\",\n",
    "      \"next\": [\n",
    "        \"000008\"\n",
    "      ],\n",
    "      \"previous\": \"000005\",\n",
    "      \"theme\": \"retro\"\n",
    "    },\n",
    "    \"000009\": {\n",
    "      \"title\": \"Loudly tell that guy to pick up key and try it on the door.\",\n",
    "      \"pageId\": \"000009\",\n",
    "      \"timestamp\": \"1180931172\",\n",
    "      \"flag\": [],\n",
    "      \"media\": [\n",
    "        \"/advimgs/jb/mspaintadventure06.gif\"\n",
    "      ],\n",
    "      \"content\": \"Despite your bellowing, the man casually opens the door and leaves.\",\n",
    "      \"next\": [\n",
    "        \"000010\"\n",
    "      ],\n",
    "      \"previous\": \"000008\",\n",
    "      \"theme\": \"retro\"\n",
    "    },\n",
    "  },...\n",
    "  \"ryanquest\": {...},  # Additional Ryanquest comic\n",
    "  \"psExtras\": {...}, # Bonus pages for Problem Sleuth\n",
    "  \"wv\": {...}, # \"Exile\" Homestuck pages, should be processed just like the \"story\" pages\n",
    "  \"faqs\": {\n",
    "    \"general\": {\n",
    "      \"title\": \"General FAQ - MS Paint Adventures\",\n",
    "      \"pageId\": \"general\",\n",
    "      \"content\": \"...\" # html\n",
    "    },\n",
    "    \"new\": {...},  # New reader guide\n",
    "    \"science\": {...},  # Science FAQ\n",
    "    \"sales\": {...}, # This one was probably not Hussie, so ignore\n",
    "  },\n",
    "  # Other keys are fully irrelevant\n",
    "\"\"\"\n",
    "\n",
    "# Function to load and process MSPA text data from mspa.json\n",
    "def load_mspa_text_data(mspa_json_path):\n",
    "    \"\"\"\n",
    "    Loads and processes MSPA text data from the given JSON file.\n",
    "\n",
    "    Args:\n",
    "        mspa_json_path (str): Path to the mspa.json file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the MSPA text data.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load the JSON data\n",
    "    with open(mspa_json_path, 'r', encoding='utf-8') as f:\n",
    "        mspa_data = json.load(f)\n",
    "\n",
    "    # Initialize an empty list to store records\n",
    "    records = []\n",
    "\n",
    "    # Sections to process\n",
    "    sections_to_process = ['story', 'wv', 'psExtras']\n",
    "\n",
    "    # Iterate over each section\n",
    "    for section in sections_to_process:\n",
    "        if section in mspa_data:\n",
    "            section_data = mspa_data[section]\n",
    "            # Iterate over each page\n",
    "            for page_id, page_content in section_data.items():\n",
    "                # Extract relevant fields\n",
    "                record = {\n",
    "                    'section': section,\n",
    "                    'pageId': page_id,\n",
    "                    'title': page_content.get('title', ''),\n",
    "                    'content': page_content.get('content', ''),\n",
    "                    'timestamp': page_content.get('timestamp', ''),\n",
    "                    'media': page_content.get('media', []),\n",
    "                    'next': page_content.get('next', []),\n",
    "                    'previous': page_content.get('previous', ''),\n",
    "                    'theme': page_content.get('theme', ''),\n",
    "                    'flag': page_content.get('flag', []),\n",
    "                }\n",
    "                records.append(record)\n",
    "        else:\n",
    "            print(f\"Section '{section}' not found in mspa.json\")\n",
    "\n",
    "    # Create a DataFrame from the records\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Now call the function and store the result in a DataFrame\n",
    "mspa_df = load_mspa_text_data(MSPA_TEXT_JSON)\n",
    "\n",
    "# Get the rows with TRY AGAIN in the title\n",
    "\n",
    "try_again_rows = mspa_df[mspa_df['title'].str.contains('Try again.', case=False)]\n",
    "try_again_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-28T16:07:55.467937Z",
     "start_time": "2024-09-28T16:07:55.339388Z"
    }
   },
   "id": "b0caa83cdb1203fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     section  pageId       title  \\\n",
       "1855   story  001895  Try again.   \n",
       "1865   story  001903  Try again.   \n",
       "2171   story  002211  Try again.   \n",
       "2627   story  002666  Try again.   \n",
       "2669   story  002710  Try again.   \n",
       "3852   story  003891  Try again.   \n",
       "3856   story  003894  Try again.   \n",
       "\n",
       "                                                content   timestamp  \\\n",
       "1855                                                     1239417163   \n",
       "1865                                                     1239607364   \n",
       "2171                                                     1246269608   \n",
       "2627                                                     1255504457   \n",
       "2669  HOT. Wait...<br /><br />No. Cold. Really cold....  1256419851   \n",
       "3852  That is much better. In fact, as it happens, y...  1276383641   \n",
       "3856  Your name is KARKAT VANTAS. As was previously ...  1276399264   \n",
       "\n",
       "                                                  media      next previous  \\\n",
       "1855                   [/storyfiles/hs/00003/00003.swf]  [001896]   001894   \n",
       "1865                        [/storyfiles/hs2/00003.gif]  [001904]   001902   \n",
       "2171                        [/storyfiles/hs2/00311.gif]  [002212]   002210   \n",
       "2627                        [/storyfiles/hs2/00766.gif]  [002667]   002665   \n",
       "2669  [/storyfiles/hs2/00810_1.gif, /storyfiles/hs2/...  [002711]   002709   \n",
       "3852                        [/storyfiles/hs2/01991.gif]  [003892]   003890   \n",
       "3856  [/storyfiles/hs2/01994_1.gif, /storyfiles/hs2/...  [003895]   003893   \n",
       "\n",
       "     theme flag  \n",
       "1855        [F]  \n",
       "1865         []  \n",
       "2171         []  \n",
       "2627         []  \n",
       "2669         []  \n",
       "3852         []  \n",
       "3856         []  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>pageId</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>media</th>\n",
       "      <th>next</th>\n",
       "      <th>previous</th>\n",
       "      <th>theme</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>story</td>\n",
       "      <td>001895</td>\n",
       "      <td>Try again.</td>\n",
       "      <td></td>\n",
       "      <td>1239417163</td>\n",
       "      <td>[/storyfiles/hs/00003/00003.swf]</td>\n",
       "      <td>[001896]</td>\n",
       "      <td>001894</td>\n",
       "      <td></td>\n",
       "      <td>[F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>story</td>\n",
       "      <td>001903</td>\n",
       "      <td>Try again.</td>\n",
       "      <td></td>\n",
       "      <td>1239607364</td>\n",
       "      <td>[/storyfiles/hs2/00003.gif]</td>\n",
       "      <td>[001904]</td>\n",
       "      <td>001902</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>story</td>\n",
       "      <td>002211</td>\n",
       "      <td>Try again.</td>\n",
       "      <td></td>\n",
       "      <td>1246269608</td>\n",
       "      <td>[/storyfiles/hs2/00311.gif]</td>\n",
       "      <td>[002212]</td>\n",
       "      <td>002210</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>story</td>\n",
       "      <td>002666</td>\n",
       "      <td>Try again.</td>\n",
       "      <td></td>\n",
       "      <td>1255504457</td>\n",
       "      <td>[/storyfiles/hs2/00766.gif]</td>\n",
       "      <td>[002667]</td>\n",
       "      <td>002665</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>story</td>\n",
       "      <td>002710</td>\n",
       "      <td>Try again.</td>\n",
       "      <td>HOT. Wait...&lt;br /&gt;&lt;br /&gt;No. Cold. Really cold....</td>\n",
       "      <td>1256419851</td>\n",
       "      <td>[/storyfiles/hs2/00810_1.gif, /storyfiles/hs2/...</td>\n",
       "      <td>[002711]</td>\n",
       "      <td>002709</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>story</td>\n",
       "      <td>003891</td>\n",
       "      <td>Try again.</td>\n",
       "      <td>That is much better. In fact, as it happens, y...</td>\n",
       "      <td>1276383641</td>\n",
       "      <td>[/storyfiles/hs2/01991.gif]</td>\n",
       "      <td>[003892]</td>\n",
       "      <td>003890</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>story</td>\n",
       "      <td>003894</td>\n",
       "      <td>Try again.</td>\n",
       "      <td>Your name is KARKAT VANTAS. As was previously ...</td>\n",
       "      <td>1276399264</td>\n",
       "      <td>[/storyfiles/hs2/01994_1.gif, /storyfiles/hs2/...</td>\n",
       "      <td>[003895]</td>\n",
       "      <td>003893</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating vizPageId from pageId\n",
    "\n",
    "The Homestuck Collection uses the MSPA page IDs, but the Homestuck website uses its own page IDs. We can convert the MSPA page IDs to the Homestuck website page IDs with some clever and totally not bruteforced heuristics."
   ],
   "id": "b4265fff89fa9d67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T16:57:42.895100Z",
     "start_time": "2024-09-28T16:57:42.891118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adventure_mapping = {\n",
    "    1: \"Jailbreak\",\n",
    "    2: \"Bard Quest\",\n",
    "    3: \"Blood Spade\",\n",
    "    4: \"Problem Sleuth\",\n",
    "    5: \"Homestuck BETA\",\n",
    "    6: \"Homestuck\"\n",
    "}\n",
    "\n",
    "# TODO"
   ],
   "id": "56d9d0e79db74e8a",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting panel transcripts from ReadMSPA plugin\n",
    "\n",
    "ReadMSPA's data (and its plugin from the collection) comes with text transcripts of every image's text, if not descriptions. We can use that."
   ],
   "id": "7769fbbcf399e4c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T16:57:54.190352Z",
     "start_time": "2024-09-28T16:57:54.047440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "The ReadMSPA data is divided in three similar files for unknown reasons, READMSPA_TRANSCRIPTS, READMSPA_ALTTEXT, READMSPA_ALTNARRATIVE. The latter tends to have way longer transcriptions, but there are long transcriptions in READMSPA_ALTTEXT, and they have different formats besides. READMSPA_TRANSCRIPTS even contains transcripts of youtube links linked in the pages, which we should preserve anyway. \n",
    "Note the keys are not equivalent to pageId. These keys use the mspaintadventures.com format, where page numbers were padded with zeroes, as well as sharing a count for every adventure in the site, from Jailbreak to Homestuck. Homestuck's first page is 001901 and it's the adventure number 6 (instead of 4 for historical reasons, but this is not really relevant to us right now).\n",
    "\n",
    "Portion of READMSPA_TRANSCRIPTS:\n",
    "```json\n",
    "{\n",
    "    \"6/001901\": [\n",
    "        {\n",
    "            \"src\": null,\n",
    "            \"alt\": \"SBURB BETA\",\n",
    "            \"contents\": \"SBURB BETA\",\n",
    "            \"id\": \"00001.gif.transcript\",\n",
    "            \"data\": null,\n",
    "            \"class\": [\n",
    "                \"transcript\"\n",
    "            ],\n",
    "            \"style\": \"background: white; color: #C1C1C1\",\n",
    "            \"tag\": \"div\"\n",
    "        }\n",
    "    ],\n",
    "    \"6/010030\": [\n",
    "        {\n",
    "            \"src\": \"http/www.youtube.com-rmzu89jy2j8.mp4\",\n",
    "            \"alt\": \"* (This transcribes both the snapchat pics from the right of the video - which as narrative, are included in readmspa.org word count stats - and the credits from the left, which are not.)\\n\\n\\nmspaofficial\\n\\nAdded Me\\nAdd Friends\\nMy Friends\\n\\n\\n* HOMESTUCK\\n\\n* BY\\n* ANDREW HUSSIE\\n\\n\\nGreetings From\\nEARTH C\\n\\n\\n* SOUND\\n* CONTRIBUTORS (A-Z)\\n\\n* Alex Rosetti\\n* Andrew Huo\\n* BurnedKirby\\n* Charlie Clouser\\n* Clark Powell\\n* Curt Blakeslee\\n* David DeCou\\n* David Ko\\n\\n\\nMAYOR\\n\\n\\n* Dianne Warren\\n* DJ Sai Tae\\n* Eddie Morton\\n* Eligecos\\n* Erik Scheele\\n* Eston Schweickart\\n* First Turn Fold\\n* Frank Haught\\n* Gabe Nezovic\\n\\n\\n* Insane Clown Posse\\n* James Roach\\n* Jan Van Den Hemel\\n* Joseph Aylsworth\\n* Kalibration\\n* Kera Jones\\n* Kevin Regamey\\n* Kezinox\\n* Malcolm Brown\\n\\n\\n* Mark Hadley\\n* Michael Guy Bowman\\n* Michael Vallejo\\n* Nick Smalley\\n* Noel Sadwin\\n* Paul Tuttle Starr\\n* Perry Sullivan\\n* Plumegeist\\n* Robert J! Lake\\n\\n\\n* Samm 413\\ntentacleTherapist\\ngallowsCallibrator\\ntipsyGnostalgic\\ngrimAuxiliatrix\\ngolgothasTerror\\ntimaeusTestified\\ngutsyGumshoe\\n\\n\\nCALIBORN: COME AT ME BRO.\\n\\n\\nJOHN: step off.\\n\\n\\nCALIBORN: COME TO MY DARK CARNIVAL. \\\"MOTHER FUCKER\\\".\\n\\n\\nJOHN: i'll do it...\\n\\n\\nCALIBORN: MAKE A MOVE. AND THE BUNNY GETS IT.\",\n",
    "            \"contents\": \"\",\n",
    "            \"id\": \"08123.mp4\",\n",
    "            \"data\": \"End Credits\",\n",
    "            \"class\": [\n",
    "                \"flash\",\n",
    "                \"alt-narrative\"\n",
    "            ],\n",
    "            \"style\": null,\n",
    "            \"tag\": \"embed\"\n",
    "        }\n",
    "    ],\n",
    "```\n",
    "\n",
    "Portion of READMSPA_ALTTEXT:\n",
    "```json\n",
    "{\n",
    "    \"advimgs/jb/mspaintadventure06.gif\": \"\\nBELLOW!\\n\\nSLAM\\n\",\n",
    "    \"advimgs/jb/mspaintadventure09d.gif\": \"CRACK\",\n",
    "    \"advimgs/jb/mspaintadventure09e.gif\": \"SLAM\",\n",
    "    \"advimgs/jb/mspaintadventure05.gif\": \"CLANK\",\n",
    "    \"advimgs/jb/mspaintadventure08.gif\": \"? ? ? ?\",\n",
    "    ...\n",
    "    \"storyfiles/hs2/07655.gif\": \"\\nDAVE: ...\\nDIRK: ...\\n\",\n",
    "    \"storyfiles/hs2/07651.gif\": \"nuzzzzzzzzzle\",\n",
    "    \"storyfiles/hs2/07650.gif\": \"nuzzzzle\",\n",
    "    \"storyfiles/hs2/07648.gif\": \"KANAYA: Shoutpole\",\n",
    "}\n",
    "\n",
    "Portion of READMSPA_ALTNARRATIVE:\n",
    "```json\n",
    "\"6/002153\": [\n",
    "        {\n",
    "            \"src\": null,\n",
    "            \"alt\": \"<style>.page[id=\\\"6/002153\\\"] .walkaround p { border-color: #23CE27; border-radius: 0;\\n\\t\\t       \\t    \\t\\t    background-color: white; max-width: 100%; }</style>\\n* Derived in part from <a href=\\\"http://pastebin.com/a3k6RgMR\\\">a transcript by ShadowOfFate</a>\\n\\n<div style=\\\"padding: 1em; background-color: white; border: solid 3px black\\\">CLICK THIS</div><dl>\\n<dt>* click it!</dt>\\n<dd>\\n<p>To walk around, use the mouse, arrow keys, or WASD keys. Click on various objects to open command menus for them!\\n\\nOutstanding Flash programming by Alexis 'Gankro' Beingessner.</p>\\n</dd>\\n\\n<dt>* click jestersprite</dt>\\n<dd>\\n<kbd>&gt; WHAT'S THAT\\n</kbd>\\n<p>It looks different now.\\n\\nAfter you bit that APPLE, your whole house seemed to be trasported somewhere. Then the APPLE disappeared and the KERNELSPRITE underwent a transformation. Aside from the change in appearance, the transformation doesn't seem to have any relevant ramifications. You still can't understand a word this idiot says.</p>\\n<kbd>&gt; THE GHOST CLOWN...\",\n",
    "            \"id\": \"00253.swf.transcript\",\n",
    "            \"data\": \"John explores his house with WV (transcript and walkthrough)\"\n",
    "        }\n",
    "    ],\n",
    "    \"6/002149\": [\n",
    "        {\n",
    "            \"src\": null,\n",
    "            \"alt\": \"* Derived from <a href=\\\"http://mspaintadventures.wikia.com/wiki/Rose%27s_Walkthrough\\\">MSPA Wiki</a>\\n\\n<p style=\\\"background-color: black; color: white; padding: 1em;\\n          font-family: Lucida Console, courier;\\\"><b>Sburb Beta FAQ/Walkthrough</b> by <span style=\\\"color: #ff6600\\\">tentacleTherapist</span>\\n<b>Hosted by</b> <span style=\\\"color: #ff6600\\\">GameFAQs</span>\\nVersion 1.0, Last Updated 2009-04-13\\n<span style=\\\"color: #ff6600\\\">View/Download Original File</span>\\nLiked this FAQ? Click to <span style=\\\"color: #ff6600\\\">recommend</span> it to other GameFAQs users.\\n</p>\\n<article style=\\\"font-family: Lucids Console, courier\\\">\\nSburb Beta Walkthrough\\nVersion 1.0, April 13, 2009\\nBy tentacleTherapist\\n\\n=============================== TABLE OF CONTENTS ===============================\\n\\n1. Caveats and Condolences........................... [0000]\\n2. Walkthrough (Incomplete).......................... [A000]\\n2.1. An Examination of the Basics.................... [A000]\\n2.2. So your cruxtruder is ticking. Do this to live.. [A100]\\n2.3. The Long and Short. The Medium too.............. [B100]\\nsome stuff about captcha codes and punch card alchemy [Z001]\\nC. Appendix 3 -- Screen Captures, pt. 1.............. [Z301]\\n?. Rose: Egress...\",\n",
    "            \"id\": \"00249_2.gif.transcript\",\n",
    "            \"data\": \"Rose's Sburb Beta Walkthrough - Caveats and Condolences\"\n",
    "        }\n",
    "    ],\n",
    "    \"6/002037\": [\n",
    "        {\n",
    "            \"src\": null,\n",
    "            \"alt\": \"* Derived from <a href=\\\"http://pastebin.com/FQhpyeKx\\\">a transcript by ShadowOfFate</a>\\n\\n<ul style=\\\"list-style: none; background-color: #4CE24E; padding: 1em;\\n    color: white; text-align: center; white-space: normal\\\">\\n<li>Transforming Soffits</li>\\n<li>Reorganizing Keys</li>\\n<li>Formalizing Immersion Joints</li>\\n<li>Justifying Kick Extractors</li>\\n<li>Advising Aggregates</li>\\n<li>Managing Elbows</li>...\",\n",
    "            \"id\": \"00137.swf.transcript\",\n",
    "            \"data\": \"Sburb Beta loading screen\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Our objective here is to combine the information so that, for each panel, we'll have its text transcript.\n",
    "\"\"\"\n",
    "\n",
    "def load_readmspa_transcripts(transcripts_path):\n",
    "    pass\n",
    "\n",
    "def load_readmspa_alttext(alttext_path):\n",
    "    pass\n",
    "\n",
    "def load_readmspa_altnarrative(altnarrative_path):\n",
    "    pass\n",
    "\n",
    "def merge_transcripts_with_mspa_df(mspa_df, alttext_df, altnarrative_df):\n",
    "    pass\n",
    "\n",
    "# Load ReadMSPA data\n",
    "alttext_df = load_readmspa_alttext(READMSPA_ALTTEXT)\n",
    "altnarrative_df = load_readmspa_altnarrative(READMSPA_ALTNARRATIVE)\n",
    "\n",
    "# Merge transcripts with the main MSPA DataFrame\n",
    "mspa_df_with_transcripts = merge_transcripts_with_mspa_df(\n",
    "    mspa_df, alttext_df, altnarrative_df)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "mspa_df_with_transcripts.sample(10)\n"
   ],
   "id": "5776d1d18e08d406",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 106\u001B[0m\n\u001B[0;32m    102\u001B[0m mspa_df_with_transcripts \u001B[38;5;241m=\u001B[39m merge_transcripts_with_mspa_df(\n\u001B[0;32m    103\u001B[0m     mspa_df, alttext_df, altnarrative_df)\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# Display the first few rows of the updated DataFrame\u001B[39;00m\n\u001B[1;32m--> 106\u001B[0m \u001B[43mmspa_df_with_transcripts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m(\u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'sample'"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting panel tags from HSSE\n",
    "\n",
    "The Homestuck Search Engine people tagged the tags of the first four acts, from characters to locations and more. Will be extremely useful for image transcription."
   ],
   "id": "b8d3d687bdf45636"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T15:42:32.056920Z",
     "start_time": "2024-09-28T15:42:31.873118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "HSSE_TAGS and HSSE_SEARCH file contain the entirety of the Homestuck Search Engine tagged data (only the first four acts, until page 1988 inclusive and excluding some swfs) in its own bespoke JSON format.\n",
    "HSSE_TAGS is the simpler json with tag definitions, and which tags contain other tags:\n",
    "```json\n",
    " \"definitions\": {\n",
    "    \"0\": {\n",
    "      \"_id\": 0,\n",
    "      \"name\": \"Character\",\n",
    "      \"children\": [\n",
    "        1,\n",
    "        32,\n",
    "        56,\n",
    "        60,\n",
    "        104,\n",
    "        132,\n",
    "        148,\n",
    "        155,\n",
    "        173,\n",
    "        184,\n",
    "        253\n",
    "      ]\n",
    "    },\n",
    "    \"1\": {\n",
    "      \"_id\": 1,\n",
    "      \"name\": \"Human\",\n",
    "      \"children\": [\n",
    "        2,\n",
    "        15\n",
    "      ]\n",
    "    },\n",
    "    \"2\": {\n",
    "      \"_id\": 2,\n",
    "      \"name\": \"Kid\",\n",
    "      \"children\": [\n",
    "        3,\n",
    "        10\n",
    "      ]\n",
    "    },\n",
    "    \"3\": {\n",
    "      \"_id\": 3,\n",
    "      \"name\": \"Beta Kid\",\n",
    "      \"children\": [\n",
    "        4,\n",
    "        5,\n",
    "        7,\n",
    "        9\n",
    "      ]\n",
    "    },\n",
    "    \"4\": {\n",
    "      \"_id\": 4,\n",
    "      \"name\": \"John Egbert\",\n",
    "      \"children\": []\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "HSSE_SEARCH is the more complex json with the actual tags for each panel:\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"_id\": 0,\n",
    "    \"type\": 0,\n",
    "    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\n",
    "    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00001.gif\",\n",
    "    \"url\": \"https://homestuck.com/story/1\",\n",
    "    \"tags\": [\n",
    "      1384,\n",
    "      1385,\n",
    "      391,\n",
    "      321,\n",
    "      4,\n",
    "      749,\n",
    "      801,\n",
    "      1301,\n",
    "      602,\n",
    "      1192,\n",
    "      711,\n",
    "      1349\n",
    "    ],\n",
    "    \"page\": 1\n",
    "  },\n",
    "  {\n",
    "    \"_id\": 1,\n",
    "    \"type\": 0,\n",
    "    \"content\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\n",
    "    \"thumbnail\": \"https://www.homestuck.com/images/storyfiles/hs2/00002.gif\",\n",
    "    \"url\": \"https://homestuck.com/story/2\",\n",
    "    \"tags\": [\n",
    "      1384,\n",
    "      1385,\n",
    "      391,\n",
    "      321,\n",
    "      4,\n",
    "      1349,\n",
    "      602\n",
    "    ],\n",
    "    \"page\": 2\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "Our objective here is to combine the information so that, for each page, we'll have its human readable tags. \n",
    "\"\"\"\n",
    "\n",
    "def load_hsse_tags(tags_path):\n",
    "    \"\"\"\n",
    "    Loads and processes the HSSE tag definitions.\n",
    "\n",
    "    Args:\n",
    "        tags_path (str): Path to the hsse_tags.json file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping tag IDs (int) to tag names (str).\n",
    "    \"\"\"\n",
    "    with open(tags_path, 'r', encoding='utf-8') as f:\n",
    "        tags_data = json.load(f)\n",
    "    \n",
    "    # Extract the 'definitions' key\n",
    "    definitions = tags_data.get('definitions', {})\n",
    "    \n",
    "    # Build mapping from _id (int) to name (str)\n",
    "    tag_id_to_name = {}\n",
    "    for tag_id_str, tag_info in definitions.items():\n",
    "        tag_id = tag_info.get('_id')\n",
    "        name = tag_info.get('name')\n",
    "        if tag_id is not None and name is not None:\n",
    "            tag_id_to_name[tag_id] = name\n",
    "    return tag_id_to_name\n",
    "\n",
    "def load_hsse_search(search_path):\n",
    "    \"\"\"\n",
    "    Loads and processes the HSSE page-tag associations.\n",
    "\n",
    "    Args:\n",
    "        search_path (str): Path to the hsse_search.json file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping page IDs (str) to lists of tag IDs (int).\n",
    "    \"\"\"\n",
    "    with open(search_path, 'r', encoding='utf-8') as f:\n",
    "        search_data = json.load(f)\n",
    "    \n",
    "    # search_data is a list of dicts\n",
    "    page_to_tag_ids = {}\n",
    "    for entry in search_data:\n",
    "        page = entry.get('page')  # integer\n",
    "        tags = entry.get('tags', [])  # list of integers\n",
    "        if page is not None:\n",
    "            page_str = str(page)  # Convert page number to string to match 'pageId'\n",
    "            page_to_tag_ids[page_str] = tags\n",
    "    \n",
    "    return page_to_tag_ids\n",
    "\n",
    "def map_tags_to_names(page_to_tag_ids, tag_id_to_name):\n",
    "    \"\"\"\n",
    "    Maps tag IDs to tag names for each page.\n",
    "\n",
    "    Args:\n",
    "        page_to_tag_ids (dict): Dictionary mapping page IDs to lists of tag IDs.\n",
    "        tag_id_to_name (dict): Dictionary mapping tag IDs to tag names.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping page IDs to lists of tag names.\n",
    "    \"\"\"\n",
    "    page_to_tag_names = {}\n",
    "    for page_id, tag_ids in page_to_tag_ids.items():\n",
    "        # Ensure tag_ids is a list\n",
    "        if not isinstance(tag_ids, list):\n",
    "            tag_ids = [tag_ids]\n",
    "        # Map each tag ID to its name, handle unknown tags gracefully\n",
    "        tag_names = [tag_id_to_name.get(tag_id, f\"Unknown Tag {tag_id}\") for tag_id in tag_ids]\n",
    "        page_to_tag_names[page_id] = tag_names\n",
    "    return page_to_tag_names\n",
    "\n",
    "def merge_tags_into_mspa_df(mspa_df, page_to_tag_names):\n",
    "    \"\"\"\n",
    "    Merges HSSE tag data into the main MSPA DataFrame.\n",
    "\n",
    "    Args:\n",
    "        mspa_df (pd.DataFrame): The main MSPA DataFrame with transcripts.\n",
    "        page_to_tag_names (dict): Dictionary mapping page IDs to lists of tag names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated MSPA DataFrame with tags incorporated.\n",
    "    \"\"\"\n",
    "    # Create a Series from the page_to_tag_names dictionary\n",
    "    tags_series = pd.Series(page_to_tag_names, name='tags')\n",
    "    \n",
    "    # Ensure that 'pageId' in both DataFrames are strings for proper merging\n",
    "    mspa_df['pageId'] = mspa_df['pageId'].astype(str)\n",
    "    tags_series.index = tags_series.index.astype(str)\n",
    "    \n",
    "    # Merge the tags into mspa_df\n",
    "    mspa_df_with_tags = mspa_df.merge(tags_series, on='pageId', how='left')\n",
    "    \n",
    "    # Replace NaN with empty lists for pages without tags\n",
    "    mspa_df_with_tags['tags'] = mspa_df_with_tags['tags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    \n",
    "    return mspa_df_with_tags\n",
    "\n",
    "# Load HSSE tag definitions\n",
    "tag_id_to_name = load_hsse_tags(HSSE_TAGS)\n",
    "print(f\"Loaded {len(tag_id_to_name)} tags from hsse_tags.json.\")\n",
    "\n",
    "# Load HSSE page-tag associations\n",
    "page_to_tag_ids = load_hsse_search(HSSE_SEARCH)\n",
    "print(f\"Loaded tag associations for {len(page_to_tag_ids)} pages from hsse_search.json.\")\n",
    "\n",
    "# Map tag IDs to tag names\n",
    "page_to_tag_names = map_tags_to_names(page_to_tag_ids, tag_id_to_name)\n",
    "print(\"Mapped tag IDs to tag names.\")\n",
    "# TODO: replace this with the proper page. It's using Viz Homestuck page numbers, not MSPA page numbers.\n",
    "mspa_df['pageId'].astype(str)\n",
    "\n",
    "# Merge tags into the main MSPA DataFrame\n",
    "# \n",
    "\n",
    "# # Display the first few rows of the updated DataFrame\n",
    "# print(mspa_df_with_tags[['pageId', 'title', 'transcript', 'tags']].head(10))"
   ],
   "id": "d7f364527cfaaabf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1427 tags from hsse_tags.json.\n",
      "Loaded tag associations for 8002 pages from hsse_search.json.\n",
      "Mapped tag IDs to tag names.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          000006\n",
       "1          000009\n",
       "2          000010\n",
       "3          000011\n",
       "4          000005\n",
       "           ...   \n",
       "10034    ps000037\n",
       "10035    ps000039\n",
       "10036    ps000034\n",
       "10037    ps000031\n",
       "10038    ps000040\n",
       "Name: pageId, Length: 10039, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extracting character appearances from POV cam \n",
    "\n",
    "The POV cam extension for Homestuck allows us to see the characters that are present in each page, and not just until page 1988, all of them. We can use this to extract character tags and somewhat make up for the lack of tags in the later pages."
   ],
   "id": "7b3267621db2deb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:22:23.261940Z",
     "start_time": "2024-09-28T14:22:23.254745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "The data from the POV cam comes in many files named after each character, like \"roxy.txt\" and \"rufioh.txt\". The format is not meant to be easily parsable, but it shouldn't be too hard to extract the data and \"invert\" it, to get the characters that appear in each page and their \"commands\".\n",
    "\n",
    "An example of the data (jade.txt):\n",
    "```\n",
    "Name: Jade\n",
    "Colour: #4AC925\n",
    "Image: jade.png\n",
    "Group: Kids\n",
    "\n",
    "Be created on meteor\n",
    "3790-3791\n",
    "3803\n",
    "3807\n",
    "3830-3831\n",
    "\n",
    "Be sent to Earth\n",
    "3840\n",
    "\n",
    "Land on factory\n",
    "3768-3769\n",
    "\n",
    "Be adopted\n",
    "3773-3775\n",
    "\n",
    "Be taken on hunt with grandfather\n",
    "Wander off with Bec\n",
    "Find present\n",
    "3029-3036\n",
    "```\n",
    "From the documentation:\n",
    "```md\n",
    "## Timeline language\n",
    "\n",
    "In the `Readable Timelines` folder are a number of files, each containing the timeline data for a single person.\n",
    "\n",
    "The files use the following format:\n",
    "\n",
    " * Page numbers or ranges of numbers to describe what pages a person's on.\n",
    "   (For A6A5A1x2 COMBO, use `-2` on the end to go through the pages two at a time)\n",
    "   eg. `6009`, `1901-2032`, or `7688-7692-2`\n",
    " * To split the timeline, indent the splintered timeline, then return to the original indentation for the alpha timeline.\n",
    "   Note that the two timelines are not connected by default, you must use the next two commands to describe how they should be joined.\n",
    " * `==>`: Jump into the next split timeline from this point\n",
    " * `<==`: Jump out of previous split timeline to this point\n",
    " * `~`: Insert another timeline here, using a person's name.\n",
    "   eg. `~ Davesprite`\n",
    "\n",
    "The following commands change properties about the current person or timeline.\n",
    "Write the exact word, then `:`, then the value you wish to set it to.\n",
    "eg. `Name: John`.\n",
    "\n",
    " * `Name`: Change the name of the current person.\n",
    " * `Colour`: Change the colour used for the links.\n",
    " * `Image`: Change the image used for the links.\n",
    " * `Group`: Change which group the links are a part of.\n",
    " * `Caption`: Give some hover-over text to the link between the previous page and the next.\n",
    "\n",
    "All lines which do not fit any of the above are ignored, like comments.\n",
    "```\n",
    "\n",
    "Here's also the timelines.py file used to compile it for the extension:\n",
    "\n",
    "```py\n",
    "from collections import defaultdict, OrderedDict\n",
    "import re\n",
    "\n",
    "from timeline_compiler.objects import Person, Link\n",
    "\n",
    "\n",
    "class Timelines:\n",
    "    patterns = {\n",
    "        \"Pages\": re.compile(\"^\\d+(-\\d+(-2)?)?$\"),\n",
    "        \"==>\": re.compile(\"^=+>$\"),\n",
    "        \"<==\": re.compile(\"^<=+$\"),\n",
    "        \"GOTO\": re.compile(\"^~\\s*[\\w ()'^]+$\", re.IGNORECASE),\n",
    "        \"Name\": re.compile(\"^Name:\\s*[\\w ()'^]+$\", re.IGNORECASE),\n",
    "        \"Colour\": re.compile(\"^Colour:\\s*#[0-9A-F]{6}$\", re.IGNORECASE),\n",
    "        \"Image\": re.compile(\"^Image:\\s*\\w+\\.\\w+$\", re.IGNORECASE),\n",
    "        \"Group\": re.compile(\"^Group:\\s*[\\w ()']+$\", re.IGNORECASE),\n",
    "        \"Caption\": re.compile(\"^Caption:\\s*[\\w ]+$\", re.IGNORECASE)\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colours = []\n",
    "        self.images = []\n",
    "        self.groups = []\n",
    "\n",
    "        self.people = OrderedDict()\n",
    "        self.next_page_links = defaultdict(list)\n",
    "\n",
    "    def get_person(self, person_name):\n",
    "        if person_name not in self.people:\n",
    "            self.people[person_name] = Person(len(self.people), person_name)\n",
    "        return self.people[person_name]\n",
    "\n",
    "    @classmethod\n",
    "    def tokenize_timeline_file(cls, timeline_file_location):\n",
    "        with open(timeline_file_location, 'r') as timeline_file:\n",
    "            yield from cls.tokenize_timeline_statements(timeline_file)\n",
    "\n",
    "    @classmethod\n",
    "    def tokenize_timeline_statements(cls, statements):\n",
    "        indent_level = 0\n",
    "        for line in statements:\n",
    "            potential_command = line.strip()\n",
    "            pattern_match = next((pattern for pattern in cls.patterns if cls.patterns[pattern].match(potential_command)), None)\n",
    "\n",
    "            if pattern_match is None:\n",
    "                continue\n",
    "\n",
    "            # Good enough in most cases\n",
    "            # May want to improve later\n",
    "            next_indent_level = len(line) - len(line.lstrip())\n",
    "            if next_indent_level > indent_level:\n",
    "                yield (\"BOT\",)\n",
    "            elif next_indent_level < indent_level:\n",
    "                yield (\"EOT\",)\n",
    "            indent_level = next_indent_level\n",
    "\n",
    "            if pattern_match == \"Pages\":\n",
    "                args = [int(s) for s in potential_command.split(\"-\")]\n",
    "                if len(args) == 1:\n",
    "                    args.append(args[0])\n",
    "                args[1] += 1\n",
    "                yield (pattern_match,) + tuple(args)\n",
    "\n",
    "            elif pattern_match == \"GOTO\":\n",
    "                yield (pattern_match, potential_command[1:].strip())\n",
    "\n",
    "            elif pattern_match in {\"Name\", \"Colour\", \"Image\", \"Group\", \"Caption\"}:\n",
    "                yield (pattern_match, potential_command.split(\":\")[1].strip())\n",
    "\n",
    "            else:\n",
    "                yield (pattern_match,)\n",
    "\n",
    "        yield (\"EOT\",)\n",
    "\n",
    "    def add_timeline(self, timeline_file_location):\n",
    "        self.exec_timeline_tokens(self.tokenize_timeline_file(timeline_file_location))\n",
    "\n",
    "    def exec_timeline_tokens(self, command_iterator, previous_pages=None, current_person=None, current_colour=None, current_image=None, current_group=None, next_caption=None):\n",
    "        # Page to pass into next splinter timeline\n",
    "        splinter_pages = []\n",
    "        # Page returned from splinter timeline\n",
    "        return_pages = []\n",
    "\n",
    "        if previous_pages is None:\n",
    "            previous_pages = []\n",
    "\n",
    "        for command, *args in command_iterator:\n",
    "            if command == \"Pages\":\n",
    "                for page_number in range(*args):\n",
    "                    next_link = Link(page_number, current_person, current_colour, current_image, current_group)\n",
    "\n",
    "                    if isinstance(current_person, Person) and current_person.first_page is None:\n",
    "                        current_person.first_page = next_link\n",
    "\n",
    "                    self.next_page_links[page_number].append(next_link)\n",
    "\n",
    "                    for page in previous_pages:\n",
    "                        page.link_to(next_link, next_caption)\n",
    "                    previous_pages = [next_link]\n",
    "                    next_caption = None\n",
    "\n",
    "            elif command == \"==>\":\n",
    "                splinter_pages = previous_pages\n",
    "\n",
    "            elif command == \"<==\":\n",
    "                previous_pages.extend(return_pages)\n",
    "\n",
    "            elif command == \"GOTO\":\n",
    "                for page in previous_pages:\n",
    "                    page.link_to(args[0])\n",
    "                previous_pages = [Link(args[0])]\n",
    "                self.next_page_links[args[0]].append(previous_pages[0])\n",
    "                next_caption = None\n",
    "\n",
    "            elif command == \"EOT\":\n",
    "                current_person.last_pages = previous_pages\n",
    "                return previous_pages\n",
    "\n",
    "            elif command == \"BOT\":\n",
    "                return_pages = self.exec_timeline_tokens(command_iterator, splinter_pages, current_person, current_colour, current_image, current_group)\n",
    "                splinter_pages = []\n",
    "\n",
    "            elif command == \"Name\":\n",
    "                current_person = self.get_person(args[0])\n",
    "\n",
    "            elif command == \"Colour\":\n",
    "                if not args[0] in self.colours:\n",
    "                    self.colours.append(args[0])\n",
    "                current_colour = self.colours.index(args[0])\n",
    "\n",
    "            elif command == \"Image\":\n",
    "                if not args[0] in self.images:\n",
    "                    self.images.append(args[0])\n",
    "                current_image = self.images.index(args[0])\n",
    "\n",
    "            elif command == \"Group\":\n",
    "                if not args[0] in self.groups:\n",
    "                    self.groups.append(args[0])\n",
    "                current_group = self.groups.index(args[0])\n",
    "\n",
    "            elif command == \"Caption\":\n",
    "                next_caption = args[0]\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "def extract_data_from_pov_cam_file(pov_cam_file: str) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "def extract_pov_cam_data():\n",
    "    pov_cam_files = os.listdir(POV_CAM_FOLDER)\n",
    "    pov_cam_data = pd.concat([extract_data_from_pov_cam_file(file) for file in pov_cam_files])\n",
    "    return pov_cam_data"
   ],
   "id": "ffcf872b5d200fc4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transcribing panels\n",
    "\n",
    "We have the panel images, we have the ReadMSPA transcripts of them, we have the point of view from the POV cam, and we have the title and text that accompanies the panels. We have some partial tagging information from the Homestuck Search engine. With that and a vision model, we might be able to successfully extract non-hallucinated information."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b474359994b684b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"characters\": [\"John Egbert\", \"Rose Lalonde\", \"Dr. Meowgon Spengler\"],\n",
      "    \"description\": \"John Egbert stands in a cluttered room, wearing a green suit with a blue tie. He is smiling and looking at a small black cat, which he has decided to name Dr. Meowgon Spengler. Rose Lalonde is asleep on the floor, with a 'Z' text bubble above her head, indicating she is sleeping. The room is messy, with various objects scattered around, including a laptop on a desk, a purple cube, and a red rocket-like object hanging from the ceiling. The wall in the background has the word 'MEOW' written repeatedly in purple.\",\n",
      "    \"locations\": [\"Rose's House\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Queries to send to the annotation model\n",
    "batch_queries = []\n",
    "system_prompt =  \"\"\"You are a professional image annotator.\n",
    "Your current project is annotating the panels of the webcomic Homestuck. You need to write a textual description as well as a list of location and character tags.\n",
    "Your input will be the image file itself, the source comic, the page title, the current POV characters and the OCR transcript of all the text in the page. For example:\n",
    "{\n",
    "    \"src\": \"005624.gif\",\n",
    "    \"title\": \"Jane: Reply\",\n",
    "    \"pov_characters\": [\"Jane Crocker\", \"Caliborn\"],\n",
    "    \"transcript\": [\"...\", \"HELP\"]\n",
    "}\n",
    "This is an example output:\n",
    "{\n",
    "    \"characters\": [\"Jane Crocker\"],\n",
    "    \"locations\": [\"Land of Crypts and Helium\", \"Jane's House\"],  # If you don't know the location, just leave it out\n",
    "    \"description\": \"Jane Crocker stands in the middle of her room, next to her bed. Jane is wearing a gray shirt with a blue monster logo on it, as well as a blue skirt. The room contains posters of movies. Outside the window we can see the Land of Crypts and Helium, a gray planet with multicolored flowers. There's a text bubble with '...' pointing to her head.\",\n",
    "}\n",
    "You should write verbose descriptions that will be useful for people who can't see the image, as well as for training image models.\n",
    "No talk; just go.\n",
    "\"\"\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "\n",
    "def annotate_panel(panel_data: dict, image_path: str) -> dict:\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": json.dumps(panel_data)\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\", \n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{encode_image(image_path)}\"\n",
    "                }\n",
    "            }\n",
    "        ]}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_panel_data(panel_id: str) -> dict:\n",
    "    # We get metadata from a variety of sources\n",
    "    # src: the image file name\n",
    "    # title, page_content: from the json archive\n",
    "    # pov_characters: from the POV extension\n",
    "    # transcript: from the ReadMSPA transcripts\n",
    "    pass\n",
    "    \n",
    "\n",
    "# We load a test panel, from HS_PANELS_FOLDER, 01691.gif which should depict a sleeping Rose and an awake John\n",
    "test_panel = os.path.join(HS_PANELS_FOLDER, \"01691.gif\")\n",
    "test_panel_data = {\n",
    "    \"src\": \"01691.gif\",\n",
    "    \"title\": \"John: Get up.\",\n",
    "    \"page_content\": \"\"\"Despite the pandemonium of your entrance, Rose is still sound asleep. She must be really tuckered out!\n",
    "<br>\n",
    "<br>It looks like this little guy is awake and ready for action though. He is adorable. You decide to name him Dr. Meowgon Spengler.\"\"\",\n",
    "    \"pov_characters\": [\"John Egbert\", \"Rose Lalonde\"],\n",
    "    \"transcript\": [\"Z\"],\n",
    "}\n",
    "\n",
    "# We'll use the OpenAI API to annotate the panel\n",
    "# This is a test, so we'll just print the output\n",
    "print(annotate_panel(test_panel_data, test_panel))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T12:06:43.588686Z",
     "start_time": "2024-05-17T12:06:39.635601Z"
    }
   },
   "id": "cedb5ad02fa9ded7",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Textual datasets\n",
    "\n",
    "We output datasets for Homestuck, MS Paint Adventures as a whole, and all of Andrew Hussie's works.\n",
    "\n",
    "The format is .jsonl"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f38d16f8b794cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-17T12:05:22.907068Z"
    }
   },
   "id": "844d7091d210b86f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
